\documentclass{beamer}
\usepackage{listings}
\usetheme{Pittsburgh}
\usecolortheme{crane}
\title{How to Miscompile Programs\\ with ``Benign'' Data Races}
\subtitle{Hans-J.\ Boehm, HotPar 2011}
\author{nick black {\texttt{<dank@qemfd.net>}}}
\institute{Atlanta PWL \#09, 2018-10-09}
\date{}
\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\frametitle{executive summary}
``Benign'' data races do not exist at the source level.
\vfill
Effects of data races depend on compilation flags, compiler version, hardware,
and OS.
\vfill
Attempts to assign semantics to data races (Java, .NET) have largely failed.
\end{frame}

\begin{frame}
\frametitle{historical context and results}
Multithread-aware memory model (declaring all data races to be errors having undefined behavior) only added to C11, C++11.
\vfill
Portable, performant atomics added by C11 \texttt{<stdatomic.h>}, C++11 \texttt{<atomic>}.
\vfill
Complex compiler/CPU technology stresses naive mental models.
\vfill
Race detection tool research at the time hoped to distinguish ``destructive'' from ``benign'' races (this paper is, in part, a response to that trend).
\vfill
Data races are difficult to detect in mainstream PRAM-model languages, Recognizing their seriousness motivated programming language research, better software engineering practices, and work on tools.
\end{frame}

\begin{frame}
\frametitle{data races, how do they work}
``We define a data race as simultaneous access to the same
memory location by multiple threads, where at least one
of the accesses modifies the memory location.''
\vfill
Essentially equivalent to e.g. Java's ``happens-before'' definitions.
\end{frame}

\begin{frame}[fragile]
\frametitle{source: let's speed up lazy init}
\begin{lstlisting}
if (!init_flag) {
  lock();
  if (!init_flag) {
    my_data = ...;
    init_flag = true;
  }
  unlock();
}
tmp = my_data;
\end{lstlisting}
\end{frame}

\begin{frame}
\frametitle{doubly-checked lazy initialization disasters}
Bad idea: Bypass ``expensive'' lock acquisition in common (initialized) case.
\vfill
Problem 1: Compiler reorders writes to \texttt{my\_data}, \texttt{init\_flag}. Thread sees a high init\_flag, but my\_data is not actually prepared, \texttt{tmp} gets bogus value.
\vfill
Problem 2: Processor reorders stores to \texttt{my\_data}, \texttt{init\_flag}. Without lock, there's no memory barrier ensuring ordering visibility, same result as above.
\vfill
Proper solutions: {\texttt{pthread\_once()}}, C++11/C11 \texttt{call\_once()}, C++11 static block scope (can be optimal), lift initialization out of concurrent path (probably optimal)
\end{frame}

\begin{frame}
\frametitle{why would this happen?}
\textit{Store motion} eliminates redundant assignments by lifting them
out of subblocks. \textit{Instruction scheduling} optimizes for instruction
cache loads, frontend decoding, and OOO resources, and can move independent
code arbitrarily. \textit{Dependency optimization} might perform a write
earlier, to have it ready by the time of its use.
\vfill
Processor store reordering is performed to eliminate redundant stores,
make better utilization of buses/caches, better balance bank accesses,
and reduce interprocessor traffic.
\end{frame}

\begin{frame}[fragile]
\frametitle{source: let's turn a light off and on}
\begin{lstlisting}
t1() {
  while(1) {
    usleep(1000);
    set_light(brightness);
  }
}

t2() {
  wait_until(event) {
    brightness = (t++ % 2) ? -1 : 1;
  }
}
\end{lstlisting}
\end{frame}

\begin{frame}
\frametitle{both values are valid, until they're not}
Bad idea: Avoid lock complexity between publisher and polling consumer signalling via a bimodal shared integer.
\vfill
Problem 1: Compiler optimizes away check entirely, as there's no way for the variable to be modified in consumer control flow. Code never runs.
\vfill
Problem 2: Architecture doesn't support integer width, compiler makes up for it in multipart software load. Alternatively, compiler materializes constant on the fly in multistep operation. Thread sees value outside the two expected values.
\vfill
Proper solution: atomics, or good ol' locks for complex data\\
  (\textit{not} \texttt{volatile}!)
\end{frame}

\begin{frame}[fragile]
\frametitle{source: let's write an arbitrary value}
\begin{lstlisting}
int my_counter = counter; // Read global
int (*my_func)(int);
if (my_counter > my_old_counter) {
  ... // Consume data
  my_func = ...;
  ... // Do some more consumer work
}
... // Do some other work
if (my_counter > my_old_counter) {
   ... my_func(...) ...
}
\end{lstlisting}
\end{frame}

\begin{frame}
\frametitle{reality is a lie}
Bad idea: Avoid lock complexity between publisher and polling consumer signalling via a shared integer where all values are acceptable.
\vfill
Problem: Compiler never actually generates temporary variable, reloading from the shared variable, which changes between conditionals. Thread ``impossibly'' branches into the grim lands of undefined behavior, is eaten by a grue.
\end{frame}

\begin{frame}[fragile]
\frametitle{source: let's count negatives}
\begin{lstlisting}
static int count = 17;

f(x) {
  for (p = x ; p ; p = p->next) {
    if (p->data < 0) {
      count++;
    }
  }
}

t1() { count = 0; f(positives); }

t2() { f(positives); count = 0; }
\end{lstlisting}
\end{frame}

\begin{frame}
\frametitle{adding writes results in fewer writes}
Bad idea: Avoid lock complexity by only writing a single constant (with only positive inputs, only 0 ought ever be written to count).
\vfill
Problem: Compiler uses register for accumulation, writes back modified result.
\end{frame}

\begin{frame}[fragile]
\frametitle{jiro dreams of zero}
\begin{lstlisting}
thread2_reg = count; // Reads 17
count = 0; // thread 1
count = thread2_reg; // Writes 17
thread1_reg = count; // Reads 17
count = 0; // thread 2
count = thread1_reg; // Writes 17, aieeeee
\end{lstlisting}
\end{frame}

\begin{frame}
\frametitle{come on mary, don't fear the mutex}
Acquisition of an uncontended Linux mutex since 2.6.0 (2003) is merely an
atomic lock instruction on a memory location. No system call, no bus locking.
no fuss.
\vfill
Locking is cheap. Contention is expensive.
\vfill
Worried about performance? \texttt{perf-lock}, you're welcome. Off-CPU analysis
can currently best be effected via perf+eBPF cantrips.
\end{frame}

\begin{frame}
\frametitle{tools and techniques for avoiding data races}
\begin{itemize}
\item Languages supporting non-PRAM models (CSP, immutable MP, etc.)
\item Scope-based RAII synchronization (C++ \texttt{std::lock\_guard})
\item Raw checkers (clang's {\texttt{scan-build}}, Java's RacerD)
\item Annotations (clang's TSA, {\texttt{javax.annotation.concurrent}})
\item Dynamic analysis tools aplenty:
\end{itemize}
\vfill
\begin{columns}
\column{.5\textwidth}
Go 1.1's \texttt{-race}
\vfill
TSan (clang 3.4+), ThreadSanitizer (gcc 4.8.1+)
\vfill
Valgrind's \texttt{helgrind}
\column{.5\textwidth}
\includegraphics[width=1\textwidth]{maxresdefault.jpg}
\end{columns}
\end{frame}
\end{document}
